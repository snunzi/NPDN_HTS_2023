2G Metabarcoding
=======================

Lecture
^^^^^^^


Introduction
^^^^^^^^^^^^
Here, we will analyze a non-routine diagnostic rice sample using 2G metabarcoding. The sample tested positive for Pantoea ananatis using a conventional PCR assay; however, qPCR data for these samples was not available.  A highly degenerate primer pair was used to amplify an ~290 bp fragment of DNA gyrase ß subunit gene (gyrB), a common phylogenetic marker present in single copy in most bacteria. Amplicons were sequenced by 2x250 Illumina MiSeq sequencing.

Identifying bacteria from amplicon sequencing data can be done with two main techniques:

* Cluster sequences into Operational Taxonomic Units (OTUs)
* Reconstruct exact sequences into Amplicon Sequence Variants (ASVs)

In this tutorial, we will focus on ASV analysis using the popular R package DADA2 https://benjjneb.github.io/dada2/.

Import Data
^^^^^^^^^^^

Lets import data from a shared history. These are raw reads, exactly how you would receive them from a sequencing company or off your own Illumina sequencer. Files that have been split (or “demultiplexed”) by sample and the barcodes/adapters have already been removed by the sequencer. There is also a curated database of ~40,000 gyrB reference sequences, which allows for the taxonomic annotation of a gyrB amplicon dataset. This database was generated by Barret et al. (2015).

.. admonition:: Hands-On: Import Metagenomic Reads from Shared History

    1. At the top of the screen click on ``Shared Data`` and select ``Histories``

    2. Find the history for ``NPDN 2023 2G Metabarcode Data`` Select the green plus sign to import into your Galaxy environment.

      * Use this link if you have trouble finding it (https://usegalaxy.eu/u/schylernunziata/h/npdn-2022-data-day-2-part-2)

Importing a Workflow
^^^^^^^^^^^^^^^^^^^^^

As you saw from the previous tutorials, many bioinformatics analysis requires multiple programs and/or steps. To reduce time spent running tools individually, they can be chained together into a pipeline or workflow. Here, we will import a workflow I put together that mimics the tutorial from the DADA2 website, here: https://benjjneb.github.io/dada2/tutorial.html

.. admonition:: Hands-On: Import DADA2 Workflow

    1. At the top of your History, click on 'Shared Data' and select 'Workflows'

    2. Search for 'NPDN' and select ``NPDN 2022 DADA2``

    3. Click the dropdown arrow next to the workflow name and select `Import`.

Running the Workflow
^^^^^^^^^^^^^^^^^^^^^
This pipeline will take several minutes to run. Let's get it started and then discuss how the workflow was built and each step in the analysis workflow.

.. admonition:: Hands-On: Run DADA2 Workflow

    1. On the top panel slick on 'Workflow'.

    2. To the right of the workflow you just imported, click the run workflow button.

    3. Select data input for the Tools 1 and 2.

        * Forward read data: ``R2A_sub_R1.fastq.gz``

        * Reverse read data: ``R2A_sub_R2.fastq.gz``

    4. At the top select 'Run Workflow'


Running Final Step DADA2
^^^^^^^^^^^^^^^^^^^^^^^^^
The final step in the DADA2 pipeline is assigning taxonomy to our error corrected merged reads.


.. admonition:: Hands-On: Run DADA2 Assign Taxonomy

    1. Search for the tool, 'dada2: assignTaxonomy and Add Species' and select.

    2. Run dada2 assignTaxonomy with the following parameters:

      * sequences to be assigned: ``dada2: removeBimeraDenovo on data 19``

      * Select a reference dataset your history or use a built-in? ``Use reference data from the history``

      * Reference data set: ``train_set_gyrB_v4.fasta``

      * Names of the taxonomic levels in the data set: ``Gene,Phylum,Class,Order,Family,Genus,Species``

    3. Leave rest as default and press 'Execute'

Blast ASVs
^^^^^^^^^^^

Let's download the results so we can organize and filter them before blasting.

.. admonition:: Hands-On: Blast ASVs

    1. Download your result files ``dada2: assignTaxonomy and addSpecies on X`` and ``dada2: removeBimeraDenovo on X``

    2. Open these files in excel, sort both by ASV and copy the read counts to the assignTaxonomy output. You should now have a table with all the ASVs with taxonomy assigned along with number of reads.

    3. Copy the sequence for the ASV with the highest read count. Paste this into blastn on NCBI https://blast.ncbi.nlm.nih.gov/Blast.cgi

  -------------------------

  .. container:: toggle

      .. container:: header

          **What is your top blast hit?**

      You should find the top hit is Pantoea ananatis. Great, we were able to id the pathogen to species! But what about the other 	Pantoea ASVs? If you have time blast these sequences, you should see this sample has a potential mixed infection.


  ----------------------------
